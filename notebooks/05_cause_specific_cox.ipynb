{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Cause-Specific Cox Proportional Hazards Models with Time-Varying Covariates\n",
    "\n",
    "This notebook fits **cause-specific Cox models** for prepayment and default using the loan-month panel data with time-varying covariates.\n",
    "\n",
    "## Methodology (Blumenstock et al. 2022)\n",
    "\n",
    "### Data Structure\n",
    "- **Interval format**: Each loan contributes multiple rows (one per month)\n",
    "- **Time-varying covariates**: Behavioral and macroeconomic variables updated each month\n",
    "- **Fold-based cross-validation**: 11 folds for robust evaluation\n",
    "\n",
    "### Covariates\n",
    "- **Static**: FICO, LTV, DTI, interest rate, original UPB\n",
    "- **Behavioral**: Balance repaid %, 12-month rolling delinquency counts\n",
    "- **Macro**: HPI changes, mortgage rate spread, Treasury rate changes, unemployment\n",
    "\n",
    "### Models\n",
    "1. Cause-specific Cox for **prepayment** (default treated as censored)\n",
    "2. Cause-specific Cox for **default** (prepayment treated as censored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Survival analysis\nfrom lifelines import CoxTimeVaryingFitter  # Correct fitter for time-varying covariates\nfrom sksurv.metrics import concordance_index_censored\n\nfrom sklearn.preprocessing import StandardScaler\n\nsns.set_style('whitegrid')\n%matplotlib inline\n\nprint(\"Imports complete.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "DATA_DIR = Path('../data/processed')\n",
    "FIGURES_DIR = Path('../reports/figures')\n",
    "MODELS_DIR = Path('../models')\n",
    "\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cross-validation folds (Blumenstock: fold 10 for hyperparameter tuning)\n",
    "TRAIN_FOLDS = list(range(10))  # Folds 0-9 for training/validation\n",
    "TUNE_FOLD = 10                  # Fold 10 for hyperparameter tuning\n",
    "\n",
    "print(f\"Training folds: {TRAIN_FOLDS}\")\n",
    "print(f\"Tuning fold: {TUNE_FOLD}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load Loan-Month Panel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loan-month panel data\n",
    "print(\"Loading loan-month panel data...\")\n",
    "panel_df = pd.read_parquet(DATA_DIR / 'loan_month_panel.parquet')\n",
    "\n",
    "print(f\"Loaded {len(panel_df):,} loan-months\")\n",
    "print(f\"Unique loans: {panel_df['loan_sequence_number'].nunique():,}\")\n",
    "print(f\"Folds: {sorted(panel_df['fold'].unique())}\")\n",
    "print(f\"Vintages: {panel_df['vintage_year'].min()} - {panel_df['vintage_year'].max()}\")\n",
    "\n",
    "print(\"\\nEvent distribution:\")\n",
    "event_names = {0: 'Censored', 1: 'Prepay', 2: 'Default'}\n",
    "terminal_events = panel_df[panel_df['event'] == 1].groupby('event_code').size()\n",
    "for code, count in terminal_events.items():\n",
    "    print(f\"  {event_names.get(code, 'Other')} (k={code}): {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "examine-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine data structure\n",
    "print(\"=== Panel Data Structure ===\")\n",
    "print(f\"\\nColumns: {list(panel_df.columns)}\")\n",
    "\n",
    "print(\"\\n=== Example: Single Loan History ===\")\n",
    "example_loan = panel_df['loan_sequence_number'].iloc[0]\n",
    "example_df = panel_df[panel_df['loan_sequence_number'] == example_loan].head(10)\n",
    "print(example_df[['loan_sequence_number', 'start', 'stop', 'event', 'event_code', \n",
    "                  'loan_age', 'bal_repaid', 't_del_30d_12m']].to_string(index=False))\n",
    "\n",
    "print(\"\\n=== Interval Format ===\")\n",
    "print(\"Each row represents interval (start, stop] where:\")\n",
    "print(\"  - start: Beginning of interval (loan_age - 1)\")\n",
    "print(\"  - stop: End of interval (loan_age)\")\n",
    "print(\"  - event: 1 if terminal event occurs at stop, 0 otherwise\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verify-interval-format",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify interval format validity\n",
    "print(\"=== Verifying Interval Format ===\")\n",
    "\n",
    "# Check start < stop\n",
    "invalid_intervals = (panel_df['start'] >= panel_df['stop']).sum()\n",
    "print(f\"Invalid intervals (start >= stop): {invalid_intervals:,}\")\n",
    "\n",
    "# Check start values\n",
    "print(f\"\\nStart value distribution:\")\n",
    "print(f\"  Min: {panel_df['start'].min()}\")\n",
    "print(f\"  Max: {panel_df['start'].max()}\")\n",
    "print(f\"  Negative starts: {(panel_df['start'] < 0).sum():,}\")\n",
    "\n",
    "# Check stop values\n",
    "print(f\"\\nStop value distribution:\")\n",
    "print(f\"  Min: {panel_df['stop'].min()}\")\n",
    "print(f\"  Max: {panel_df['stop'].max()}\")\n",
    "\n",
    "# For lifelines, start must be >= 0\n",
    "# Since loan_age starts at 1, start = loan_age - 1 starts at 0\n",
    "if panel_df['start'].min() < 0:\n",
    "    print(\"\\n⚠ Warning: Negative start values found. Adjusting...\")\n",
    "    # This shouldn't happen with loan_age starting at 1\n",
    "else:\n",
    "    print(\"\\n✓ All start values are non-negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "features-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Define Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-features",
   "metadata": {},
   "outputs": [],
   "source": "# Define feature groups (Blumenstock et al. 2022, Table 2)\n\n# Static covariates (fixed at origination) - 5 variables\nSTATIC_FEATURES = [\n    'int_rate',      # Initial interest rate\n    'orig_upb',      # Original unpaid balance\n    'fico_score',    # Initial FICO score\n    'dti_r',         # Initial debt-to-income ratio\n    'ltv_r',         # Initial loan-to-value ratio\n]\n\n# Behavioral covariates (time-varying) - 4 variables\nBEHAVIORAL_FEATURES = [\n    'bal_repaid',      # Current repaid balance in percent\n    't_act_12m',       # No. of times not being delinquent in last 12 months\n    't_del_30d_12m',   # No. of times being 30 days delinquent in last 12 months\n    't_del_60d_12m',   # No. of times being 60 days delinquent in last 12 months\n]\n\n# Macro covariates (time-varying) - 12 variables from Blumenstock Table 2\nMACRO_FEATURES = [\n    # Origination-relative differences\n    'hpi_st_d_t_o',    # HPI difference between origination and today (state)\n    'ppi_c_FRMA',      # Current prepayment incentive (loan rate - current mortgage rate)\n    'TB10Y_d_t_o',     # Treasury rate difference (today - origination)\n    'FRMA30Y_d_t_o',   # 30Y FRM difference (today - origination)\n    'ppi_o_FRMA',      # Prepayment incentive at origination (loan rate - orig mortgage rate)\n    \n    # State-level variables\n    'hpi_st_log12m',   # HPI 12-month log return (state)\n    'hpi_r_st_us',     # Ratio of state HPI to national HPI\n    'st_unemp_r12m',   # Unemployment 12-month log return (state)\n    'st_unemp_r3m',    # Unemployment 3-month log return (state)\n    \n    # National macro variables\n    'TB10Y_r12m',      # Treasury rate 12-month return\n    'T10Y3MM',         # Yield spread (10Y - 3M)\n    'T10Y3MM_r12m',    # Yield spread 12-month return\n]\n\n# All features (9 loan-level + 12 macro = 21 total, matching Blumenstock Dataset 2)\nALL_FEATURES = STATIC_FEATURES + BEHAVIORAL_FEATURES + MACRO_FEATURES\n\n# Filter to available features\navailable_features = [f for f in ALL_FEATURES if f in panel_df.columns]\nmissing_features = [f for f in ALL_FEATURES if f not in panel_df.columns]\n\nprint(\"=== Feature Groups (Blumenstock et al. 2022) ===\")\nprint(f\"Static features: {len([f for f in STATIC_FEATURES if f in available_features])}/5\")\nprint(f\"Behavioral features: {len([f for f in BEHAVIORAL_FEATURES if f in available_features])}/4\")\nprint(f\"Macro features: {len([f for f in MACRO_FEATURES if f in available_features])}/12\")\nprint(f\"\\nTotal available: {len(available_features)}/21\")\nif missing_features:\n    print(f\"\\nMissing features ({len(missing_features)}):\")\n    for f in missing_features:\n        print(f\"  - {f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-model-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare modeling data\n",
    "print(\"=== Preparing Model Data ===\")\n",
    "\n",
    "# Required columns for interval-censored Cox regression\n",
    "required_cols = ['start', 'stop', 'event', 'event_code', 'fold', 'loan_sequence_number']\n",
    "model_cols = required_cols + available_features\n",
    "\n",
    "# Filter to complete cases\n",
    "df_model = panel_df[model_cols].copy()\n",
    "n_before = len(df_model)\n",
    "df_model = df_model.dropna(subset=available_features)\n",
    "n_after = len(df_model)\n",
    "\n",
    "print(f\"Rows before dropna: {n_before:,}\")\n",
    "print(f\"Rows after dropna: {n_after:,}\")\n",
    "print(f\"Dropped: {n_before - n_after:,} ({(n_before - n_after) / n_before * 100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nUnique loans: {df_model['loan_sequence_number'].nunique():,}\")\n",
    "\n",
    "# Log transform UPB for better coefficient interpretation\n",
    "if 'orig_upb' in df_model.columns:\n",
    "    df_model['log_upb'] = np.log(df_model['orig_upb'])\n",
    "    # Replace orig_upb with log_upb in feature list\n",
    "    available_features = [f if f != 'orig_upb' else 'log_upb' for f in available_features]\n",
    "    print(\"\\n✓ Created log_upb (log of original UPB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check feature coverage\n",
    "print(\"=== Feature Coverage ===\")\n",
    "for feature in available_features:\n",
    "    coverage = df_model[feature].notna().mean()\n",
    "    print(f\"  {feature}: {coverage:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Split Data by Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by folds (Blumenstock methodology)\n",
    "print(\"=== Splitting Data by Folds ===\")\n",
    "\n",
    "# Training set: folds 0-9\n",
    "train_df = df_model[df_model['fold'].isin(TRAIN_FOLDS)].copy()\n",
    "\n",
    "# Tuning set: fold 10\n",
    "tune_df = df_model[df_model['fold'] == TUNE_FOLD].copy()\n",
    "\n",
    "print(f\"Training set (folds 0-9):\")\n",
    "print(f\"  Loan-months: {len(train_df):,}\")\n",
    "print(f\"  Unique loans: {train_df['loan_sequence_number'].nunique():,}\")\n",
    "\n",
    "print(f\"\\nTuning set (fold 10):\")\n",
    "print(f\"  Loan-months: {len(tune_df):,}\")\n",
    "print(f\"  Unique loans: {tune_df['loan_sequence_number'].nunique():,}\")\n",
    "\n",
    "# Event distribution in training set\n",
    "print(\"\\nTraining set event distribution:\")\n",
    "train_events = train_df[train_df['event'] == 1].groupby('event_code').size()\n",
    "for code, count in train_events.items():\n",
    "    print(f\"  {event_names.get(code, 'Other')}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepay-model-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cause-Specific Cox Model for Prepayment\n",
    "\n",
    "Fit Cox model with time-varying covariates where:\n",
    "- **Event** = prepayment (event_code = 1)\n",
    "- **Censored** = default, actual censoring, and ongoing observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-prepay-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for prepayment model (cause-specific)\n",
    "print(\"=== Preparing Prepayment Model Data ===\")\n",
    "\n",
    "# Create prepayment-specific event indicator\n",
    "# Prepay = 1, everything else (default, censored) = 0\n",
    "train_prepay = train_df.copy()\n",
    "train_prepay['event_prepay'] = ((train_prepay['event'] == 1) & \n",
    "                                 (train_prepay['event_code'] == 1)).astype(int)\n",
    "\n",
    "tune_prepay = tune_df.copy()\n",
    "tune_prepay['event_prepay'] = ((tune_prepay['event'] == 1) & \n",
    "                                (tune_prepay['event_code'] == 1)).astype(int)\n",
    "\n",
    "print(f\"Training prepayments: {train_prepay['event_prepay'].sum():,}\")\n",
    "print(f\"Tuning prepayments: {tune_prepay['event_prepay'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-prepay-model",
   "metadata": {},
   "outputs": [],
   "source": "# Fit cause-specific Cox model for prepayment with time-varying covariates\nprint(\"=== Fitting Cause-Specific Cox Model: PREPAYMENT ===\")\n\n# Columns for CoxTimeVaryingFitter\n# Requires: id_col, start, stop, event, and covariates\ncox_cols = ['loan_sequence_number', 'start', 'stop', 'event_prepay'] + available_features\n\n# Fit model with penalization for stability\nctv_prepay = CoxTimeVaryingFitter(penalizer=0.01)\nctv_prepay.fit(\n    train_prepay[cox_cols],\n    id_col='loan_sequence_number',\n    start_col='start',\n    stop_col='stop',\n    event_col='event_prepay',\n    show_progress=True\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"PREPAYMENT MODEL RESULTS\")\nprint(\"=\" * 60)\nctv_prepay.print_summary()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-prepay-coef",
   "metadata": {},
   "outputs": [],
   "source": "# Plot hazard ratios for prepayment model\nfig, ax = plt.subplots(figsize=(10, 8))\nctv_prepay.plot(ax=ax)\nax.set_title('Cause-Specific Cox Model: Prepayment\\nHazard Ratios (95% CI)', fontsize=14)\nax.axvline(x=0, color='black', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.savefig(FIGURES_DIR / 'cox_prepay_hazard_ratios_tv.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepay-cindex",
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate prepayment model on tuning set\nprint(\"=== Prepayment Model Evaluation (Tuning Set) ===\")\n\n# Get terminal observations only for C-index calculation\n# (each loan should have exactly one terminal observation)\ntune_terminal = tune_df.groupby('loan_sequence_number').last().reset_index()\ntune_terminal['event_prepay'] = (tune_terminal['event_code'] == 1).astype(int)\n\n# Compute risk scores using model coefficients\n# Use the model's coefficient index to ensure correct feature alignment\nmodel_features = ctv_prepay.params_.index.tolist()\nX_tune = tune_terminal[model_features].values\ncoefs = ctv_prepay.params_.values\n\n# Risk = exp(X @ beta) - higher means higher hazard\nrisk_prepay = np.exp(X_tune @ coefs)\n\n# Calculate C-index\nc_index_prepay = concordance_index_censored(\n    tune_terminal['event_prepay'].astype(bool),\n    tune_terminal['stop'],\n    risk_prepay.flatten()\n)\n\nprint(f\"Prepayment Model - Tuning Set C-index: {c_index_prepay[0]:.4f}\")\nprint(f\"  Concordant pairs: {c_index_prepay[1]:,}\")\nprint(f\"  Discordant pairs: {c_index_prepay[2]:,}\")\nprint(f\"  Tied pairs: {c_index_prepay[3]:,}\")"
  },
  {
   "cell_type": "markdown",
   "id": "default-model-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cause-Specific Cox Model for Default\n",
    "\n",
    "Fit Cox model with time-varying covariates where:\n",
    "- **Event** = default (event_code = 2)\n",
    "- **Censored** = prepayment, actual censoring, and ongoing observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-default-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for default model (cause-specific)\n",
    "print(\"=== Preparing Default Model Data ===\")\n",
    "\n",
    "# Create default-specific event indicator\n",
    "# Default = 1, everything else (prepay, censored) = 0\n",
    "train_default = train_df.copy()\n",
    "train_default['event_default'] = ((train_default['event'] == 1) & \n",
    "                                   (train_default['event_code'] == 2)).astype(int)\n",
    "\n",
    "tune_default = tune_df.copy()\n",
    "tune_default['event_default'] = ((tune_default['event'] == 1) & \n",
    "                                  (tune_default['event_code'] == 2)).astype(int)\n",
    "\n",
    "print(f\"Training defaults: {train_default['event_default'].sum():,}\")\n",
    "print(f\"Tuning defaults: {tune_default['event_default'].sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-default-model",
   "metadata": {},
   "outputs": [],
   "source": "# Fit cause-specific Cox model for default with time-varying covariates\nprint(\"=== Fitting Cause-Specific Cox Model: DEFAULT ===\")\n\n# Columns for CoxTimeVaryingFitter\ncox_cols = ['loan_sequence_number', 'start', 'stop', 'event_default'] + available_features\n\n# Fit model with penalization for stability\nctv_default = CoxTimeVaryingFitter(penalizer=0.01)\nctv_default.fit(\n    train_default[cox_cols],\n    id_col='loan_sequence_number',\n    start_col='start',\n    stop_col='stop',\n    event_col='event_default',\n    show_progress=True\n)\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"DEFAULT MODEL RESULTS\")\nprint(\"=\" * 60)\nctv_default.print_summary()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-default-coef",
   "metadata": {},
   "outputs": [],
   "source": "# Plot hazard ratios for default model\nfig, ax = plt.subplots(figsize=(10, 8))\nctv_default.plot(ax=ax)\nax.set_title('Cause-Specific Cox Model: Default\\nHazard Ratios (95% CI)', fontsize=14)\nax.axvline(x=0, color='black', linestyle='--', alpha=0.5)\nplt.tight_layout()\nplt.savefig(FIGURES_DIR / 'cox_default_hazard_ratios_tv.png', dpi=150, bbox_inches='tight')\nplt.show()"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "default-cindex",
   "metadata": {},
   "outputs": [],
   "source": "# Evaluate default model on tuning set\nprint(\"=== Default Model Evaluation (Tuning Set) ===\")\n\n# Get terminal observations (reuse tune_terminal from prepay evaluation)\ntune_terminal['event_default'] = (tune_terminal['event_code'] == 2).astype(int)\n\n# Compute risk scores using model coefficients\n# Use the model's coefficient index to ensure correct feature alignment\nmodel_features = ctv_default.params_.index.tolist()\nX_tune = tune_terminal[model_features].values\ncoefs = ctv_default.params_.values\n\n# Risk = exp(X @ beta) - higher means higher hazard\nrisk_default = np.exp(X_tune @ coefs)\n\n# Calculate C-index\nc_index_default = concordance_index_censored(\n    tune_terminal['event_default'].astype(bool),\n    tune_terminal['stop'],\n    risk_default.flatten()\n)\n\nprint(f\"Default Model - Tuning Set C-index: {c_index_default[0]:.4f}\")\nprint(f\"  Concordant pairs: {c_index_default[1]:,}\")\nprint(f\"  Discordant pairs: {c_index_default[2]:,}\")\nprint(f\"  Tied pairs: {c_index_default[3]:,}\")"
  },
  {
   "cell_type": "markdown",
   "id": "comparison-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Compare Coefficients: Prepayment vs Default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compare-coefs",
   "metadata": {},
   "outputs": [],
   "source": "# Extract and compare coefficients\nprepay_coefs = ctv_prepay.summary[['coef', 'exp(coef)', 'p']].copy()\nprepay_coefs.columns = ['coef_prepay', 'hr_prepay', 'p_prepay']\n\ndefault_coefs = ctv_default.summary[['coef', 'exp(coef)', 'p']].copy()\ndefault_coefs.columns = ['coef_default', 'hr_default', 'p_default']\n\n# Combine\ncomparison = prepay_coefs.join(default_coefs)\ncomparison['coef_diff'] = comparison['coef_prepay'] - comparison['coef_default']\ncomparison['effect_direction'] = np.where(\n    comparison['coef_prepay'] * comparison['coef_default'] > 0,\n    'Same', 'Opposite'\n)\n\nprint(\"=== Coefficient Comparison: Prepayment vs Default ===\")\nprint(comparison.round(4).to_string())"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot coefficient comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "# Left: Bar chart of coefficients\n",
    "ax = axes[0]\n",
    "x = np.arange(len(available_features))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.barh(x - width/2, comparison['coef_prepay'], width, \n",
    "                label='Prepayment', color='steelblue', alpha=0.7)\n",
    "bars2 = ax.barh(x + width/2, comparison['coef_default'], width, \n",
    "                label='Default', color='indianred', alpha=0.7)\n",
    "\n",
    "ax.axvline(x=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_xlabel('Coefficient')\n",
    "ax.set_title('Cause-Specific Cox Coefficients', fontsize=12)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(available_features)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Right: Hazard ratios\n",
    "ax = axes[1]\n",
    "ax.barh(x - width/2, comparison['hr_prepay'], width, \n",
    "        label='Prepayment', color='steelblue', alpha=0.7)\n",
    "ax.barh(x + width/2, comparison['hr_default'], width, \n",
    "        label='Default', color='indianred', alpha=0.7)\n",
    "\n",
    "ax.axvline(x=1, color='black', linestyle='--', linewidth=0.5)\n",
    "ax.set_ylabel('Feature')\n",
    "ax.set_xlabel('Hazard Ratio')\n",
    "ax.set_title('Cause-Specific Hazard Ratios', fontsize=12)\n",
    "ax.set_yticks(x)\n",
    "ax.set_yticklabels(available_features)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'cox_coefficient_comparison_tv.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interpret-coefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpretation of key coefficients\n",
    "print(\"=== Key Coefficient Interpretations ===\")\n",
    "\n",
    "def interpret_coef(name, hr_prepay, hr_default, p_prepay, p_default):\n",
    "    print(f\"\\n{name}:\")\n",
    "    \n",
    "    # Prepayment effect\n",
    "    if p_prepay < 0.05:\n",
    "        if hr_prepay > 1:\n",
    "            print(f\"  Prepayment: +1 unit → {(hr_prepay-1)*100:.1f}% higher prepay hazard\")\n",
    "        else:\n",
    "            print(f\"  Prepayment: +1 unit → {(1-hr_prepay)*100:.1f}% lower prepay hazard\")\n",
    "    else:\n",
    "        print(f\"  Prepayment: Not significant (p={p_prepay:.3f})\")\n",
    "    \n",
    "    # Default effect\n",
    "    if p_default < 0.05:\n",
    "        if hr_default > 1:\n",
    "            print(f\"  Default: +1 unit → {(hr_default-1)*100:.1f}% higher default hazard\")\n",
    "        else:\n",
    "            print(f\"  Default: +1 unit → {(1-hr_default)*100:.1f}% lower default hazard\")\n",
    "    else:\n",
    "        print(f\"  Default: Not significant (p={p_default:.3f})\")\n",
    "\n",
    "# Key variables to interpret\n",
    "key_vars = ['fico_score', 'ltv_r', 'ppi_c_FRMA', 'bal_repaid', 't_del_30d_12m', 'hpi_st_d_t_o']\n",
    "key_vars = [v for v in key_vars if v in comparison.index]\n",
    "\n",
    "for var in key_vars:\n",
    "    interpret_coef(\n",
    "        var,\n",
    "        comparison.loc[var, 'hr_prepay'],\n",
    "        comparison.loc[var, 'hr_default'],\n",
    "        comparison.loc[var, 'p_prepay'],\n",
    "        comparison.loc[var, 'p_default']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"CAUSE-SPECIFIC COX MODELS WITH TIME-VARYING COVARIATES - SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nData:\")\n",
    "print(f\"  Training loan-months: {len(train_df):,}\")\n",
    "print(f\"  Training unique loans: {train_df['loan_sequence_number'].nunique():,}\")\n",
    "print(f\"  Tuning loan-months: {len(tune_df):,}\")\n",
    "print(f\"  Tuning unique loans: {tune_df['loan_sequence_number'].nunique():,}\")\n",
    "\n",
    "print(f\"\\nFeatures: {len(available_features)}\")\n",
    "print(f\"  Static: {len([f for f in STATIC_FEATURES if f in available_features or f.replace('orig_upb', 'log_upb') in available_features])}\")\n",
    "print(f\"  Behavioral (time-varying): {len([f for f in BEHAVIORAL_FEATURES if f in available_features])}\")\n",
    "print(f\"  Macro (time-varying): {len([f for f in MACRO_FEATURES if f in available_features])}\")\n",
    "\n",
    "print(f\"\\nPrepayment Model:\")\n",
    "print(f\"  Tuning C-index: {c_index_prepay[0]:.4f}\")\n",
    "print(f\"  Training prepayments: {train_prepay['event_prepay'].sum():,}\")\n",
    "\n",
    "print(f\"\\nDefault Model:\")\n",
    "print(f\"  Tuning C-index: {c_index_default[0]:.4f}\")\n",
    "print(f\"  Training defaults: {train_default['event_default'].sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-models-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-models",
   "metadata": {},
   "outputs": [],
   "source": "import pickle\n\n# Save models\nwith open(MODELS_DIR / 'cox_prepay_tv.pkl', 'wb') as f:\n    pickle.dump(ctv_prepay, f)\n    \nwith open(MODELS_DIR / 'cox_default_tv.pkl', 'wb') as f:\n    pickle.dump(ctv_default, f)\n\n# Save feature list\nwith open(MODELS_DIR / 'cox_features.pkl', 'wb') as f:\n    pickle.dump(available_features, f)\n\n# Save comparison table\ncomparison.to_csv(MODELS_DIR / 'cox_coefficient_comparison.csv')\n\nprint(f\"Models saved to {MODELS_DIR}:\")\nprint(f\"  - cox_prepay_tv.pkl (CoxTimeVaryingFitter)\")\nprint(f\"  - cox_default_tv.pkl (CoxTimeVaryingFitter)\")\nprint(f\"  - cox_features.pkl\")\nprint(f\"  - cox_coefficient_comparison.csv\")"
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "### Completed\n",
    "- ✅ Loaded loan-month panel data with time-varying covariates\n",
    "- ✅ Fit cause-specific Cox model for prepayment\n",
    "- ✅ Fit cause-specific Cox model for default\n",
    "- ✅ Evaluated models on tuning set (C-index)\n",
    "- ✅ Compared coefficient effects between models\n",
    "\n",
    "### Key Findings\n",
    "- Time-varying covariates capture dynamic risk factors\n",
    "- Behavioral variables (delinquency history) strongly predict default\n",
    "- Prepayment incentive (rate spread) drives prepayment hazard\n",
    "- HPI changes affect both prepayment and default risks\n",
    "\n",
    "### Future Work\n",
    "1. **Cross-validation**: Use folds 0-9 for k-fold cross-validation\n",
    "2. **Fine-Gray models**: Subdistribution hazard for cumulative incidence\n",
    "3. **Deep learning**: DeepSurv or DeepHit for non-linear effects\n",
    "4. **Calibration**: Assess predicted vs actual cumulative incidence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}