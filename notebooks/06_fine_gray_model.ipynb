{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Fine-Gray Subdistribution Hazard Model\n",
    "\n",
    "This notebook implements the **Fine-Gray competing risks model** using a discrete-time approximation. The Fine-Gray model estimates the subdistribution hazard, which directly relates to the cumulative incidence function.\n",
    "\n",
    "## Key Concepts\n",
    "\n",
    "| Model | Estimates | Risk Set | Use Case |\n",
    "|-------|-----------|----------|----------|\n",
    "| **Cause-specific Cox** | Hazard among those at risk | Subjects leave at any event | Etiology, risk factors |\n",
    "| **Fine-Gray** | Subdistribution hazard | Competing events stay in risk set | Cumulative incidence prediction |\n",
    "\n",
    "## Why Discrete-Time?\n",
    "\n",
    "1. Fine-Gray with time-varying covariates is mathematically complex\n",
    "2. Discrete-time is equivalent in the limit\n",
    "3. Easy to implement with standard tools\n",
    "4. Used in practice at major mortgage institutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Competing risks module\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from src.competing_risks import (\n",
    "    DiscreteTimeFineGray,\n",
    "    fit_discrete_time_competing_risks,\n",
    "    create_fine_gray_dataset,\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import statsmodels.api as sm\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "For discrete-time Fine-Gray, we ideally need the loan-month panel. If not available, we'll use the survival data with approximations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "load-data",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading loan-month panel data...\n",
      "Loaded 5,462,536 records\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = Path('../data/processed')\n",
    "\n",
    "# Try to load loan-month panel, fall back to survival data\n",
    "panel_path = DATA_DIR / 'loan_month_panel.parquet'\n",
    "survival_path = DATA_DIR / 'survival_data.parquet'\n",
    "\n",
    "if panel_path.exists():\n",
    "    print(\"Loading loan-month panel data...\")\n",
    "    df = pd.read_parquet(panel_path)\n",
    "    use_panel = True\n",
    "else:\n",
    "    print(\"Loan-month panel not found. Loading survival data...\")\n",
    "    print(\"(Run notebook 03 first to create the panel)\")\n",
    "    df = pd.read_parquet(survival_path)\n",
    "    use_panel = False\n",
    "    \n",
    "    # Create event code\n",
    "    event_map = {\n",
    "        'censored': 0, 'prepay': 1, 'default': 2,\n",
    "        'matured': 0, 'other': 3, 'defect': 3,\n",
    "    }\n",
    "    df['event_code'] = df['event_type'].map(event_map)\n",
    "\n",
    "print(f\"Loaded {len(df):,} records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-data",
   "metadata": {},
   "outputs": [],
   "source": "# Define feature groups (Blumenstock et al. 2022, Table 2)\n# Matching notebook 05 (Cause-Specific Cox) exactly\n\n# Static covariates (fixed at origination) - 5 variables\nSTATIC_FEATURES = [\n    'int_rate',      # Initial interest rate\n    'orig_upb',      # Original unpaid balance\n    'fico_score',    # Initial FICO score\n    'dti_r',         # Initial debt-to-income ratio\n    'ltv_r',         # Initial loan-to-value ratio\n]\n\n# Behavioral covariates (time-varying) - 4 variables\nBEHAVIORAL_FEATURES = [\n    'bal_repaid',      # Current repaid balance in percent\n    't_act_12m',       # No. of times not being delinquent in last 12 months\n    't_del_30d_12m',   # No. of times being 30 days delinquent in last 12 months\n    't_del_60d_12m',   # No. of times being 60 days delinquent in last 12 months\n]\n\n# Macro covariates (time-varying) - 12 variables from Blumenstock Table 2\nMACRO_FEATURES = [\n    # Origination-relative differences\n    'hpi_st_d_t_o',    # HPI difference between origination and today (state)\n    'ppi_c_FRMA',      # Current prepayment incentive (loan rate - current mortgage rate)\n    'TB10Y_d_t_o',     # Treasury rate difference (today - origination)\n    'FRMA30Y_d_t_o',   # 30Y FRM difference (today - origination)\n    'ppi_o_FRMA',      # Prepayment incentive at origination (loan rate - orig mortgage rate)\n    \n    # State-level variables\n    'hpi_st_log12m',   # HPI 12-month log return (state)\n    'hpi_r_st_us',     # Ratio of state HPI to national HPI\n    'st_unemp_r12m',   # Unemployment 12-month log return (state)\n    'st_unemp_r3m',    # Unemployment 3-month log return (state)\n    \n    # National macro variables\n    'TB10Y_r12m',      # Treasury rate 12-month return\n    'T10Y3MM',         # Yield spread (10Y - 3M)\n    'T10Y3MM_r12m',    # Yield spread 12-month return\n]\n\n# All features (9 loan-level + 12 macro = 21 total, matching Blumenstock Dataset 2)\nALL_FEATURES = STATIC_FEATURES + BEHAVIORAL_FEATURES + MACRO_FEATURES\n\nif use_panel:\n    time_col = 'loan_age'\n    event_col = 'event_code'\nelse:\n    time_col = 'duration'\n    event_col = 'event_code'\n\n# Filter to available features\nfeature_cols = [f for f in ALL_FEATURES if f in df.columns]\nmissing_features = [f for f in ALL_FEATURES if f not in df.columns]\n\nprint(\"=== Feature Groups (Blumenstock et al. 2022) ===\")\nprint(f\"Static features: {len([f for f in STATIC_FEATURES if f in feature_cols])}/5\")\nprint(f\"Behavioral features: {len([f for f in BEHAVIORAL_FEATURES if f in feature_cols])}/4\")\nprint(f\"Macro features: {len([f for f in MACRO_FEATURES if f in feature_cols])}/12\")\nprint(f\"\\nTotal available: {len(feature_cols)}/21\")\n\nif missing_features:\n    print(f\"\\nMissing features ({len(missing_features)}):\")\n    for f in missing_features:\n        print(f\"  - {f}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-model-data",
   "metadata": {},
   "outputs": [],
   "source": "# Prepare modeling data\nprint(\"=== Preparing Model Data ===\")\n\n# Required columns for modeling and train-test split\nrequired_cols = [time_col, event_col, 'loan_sequence_number', 'fold']\n\nif not use_panel:\n    # Work with one record per loan (terminal)\n    available_cols = [c for c in feature_cols + required_cols if c in df.columns]\n    df_model = df[available_cols].dropna(subset=feature_cols).copy()\nelse:\n    # Use panel data directly\n    extra_cols = ['is_terminal'] if 'is_terminal' in df.columns else []\n    available_cols = [c for c in feature_cols + required_cols + extra_cols if c in df.columns]\n    df_model = df[available_cols].dropna(subset=feature_cols).copy()\n\n# Log transform UPB for better coefficient interpretation (matching notebook 05)\nif 'orig_upb' in df_model.columns:\n    df_model['log_upb'] = np.log(df_model['orig_upb'])\n    # Replace orig_upb with log_upb in feature list\n    feature_cols = [f if f != 'orig_upb' else 'log_upb' for f in feature_cols]\n    print(\"✓ Created log_upb (log of original UPB)\")\n\nprint(f\"Model data: {len(df_model):,} records\")\nprint(f\"Unique loans: {df_model['loan_sequence_number'].nunique():,}\")\nprint(f\"Folds: {sorted(df_model['fold'].unique())}\")\nprint(f\"Features ({len(feature_cols)}): {feature_cols}\")"
  },
  {
   "cell_type": "markdown",
   "id": "fine-gray-prep-header",
   "metadata": {},
   "source": [
    "## Prepare Fine-Gray Dataset\n",
    "\n",
    "In Fine-Gray, subjects with competing events remain in the risk set (with event=0) for the primary event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fine-gray-prep",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Fine-Gray formatted dataset for prepayment (event=1)\n",
    "# In Fine-Gray:\n",
    "# - Primary event (prepay=1) -> y = 1\n",
    "# - Competing event (default=2) -> y = 0, but STAY in risk set\n",
    "# - Censored -> y = 0\n",
    "\n",
    "df_fg = df_model.copy()\n",
    "df_fg['y_prepay'] = (df_fg[event_col] == 1).astype(int)\n",
    "df_fg['y_default'] = (df_fg[event_col] == 2).astype(int)\n",
    "\n",
    "print(\"Fine-Gray outcome distribution:\")\n",
    "print(f\"  Prepay (y=1): {df_fg['y_prepay'].sum():,}\")\n",
    "print(f\"  Non-prepay (y=0): {(df_fg['y_prepay'] == 0).sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-test-split",
   "metadata": {},
   "outputs": [],
   "source": "# Train-test split using fold structure from loan_month_panel\n# Matching notebook 05 (Cause-Specific Cox) methodology\n# Folds 0-9 for training, fold 10 for testing/tuning\n\nTRAIN_FOLDS = list(range(10))\nTEST_FOLD = 10\n\ntrain_df = df_fg[df_fg['fold'].isin(TRAIN_FOLDS)].copy()\ntest_df = df_fg[df_fg['fold'] == TEST_FOLD].copy()\n\nprint(\"Using Blumenstock fold structure (from loan_month_panel):\")\nprint(f\"  Training folds: {TRAIN_FOLDS}\")\nprint(f\"  Test fold: {TEST_FOLD}\")\nprint(f\"\\nTraining: {len(train_df):,} records ({train_df['loan_sequence_number'].nunique():,} loans)\")\nprint(f\"Test: {len(test_df):,} records ({test_df['loan_sequence_number'].nunique():,} loans)\")"
  },
  {
   "cell_type": "markdown",
   "id": "fit-model-header",
   "metadata": {},
   "source": [
    "## Fit Discrete-Time Fine-Gray Model\n",
    "\n",
    "We use logistic regression to model the discrete-time subdistribution hazard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-sklearn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_df[feature_cols])\n",
    "X_test = scaler.transform(test_df[feature_cols])\n",
    "\n",
    "y_train = train_df['y_prepay'].values\n",
    "y_test = test_df['y_prepay'].values\n",
    "\n",
    "# Fit logistic regression (sklearn)\n",
    "fg_model = LogisticRegression(C=1.0, penalty='l2', solver='lbfgs', max_iter=1000)\n",
    "fg_model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Discrete-time Fine-Gray model fitted (sklearn)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-statsmodels",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also fit with statsmodels for inference (p-values, CIs)\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "X_test_sm = sm.add_constant(X_test)\n",
    "\n",
    "fg_sm = sm.Logit(y_train, X_train_sm)\n",
    "fg_result = fg_sm.fit(disp=False)\n",
    "\n",
    "print(\"\\n=== Fine-Gray Model Summary (Prepayment) ===\")\n",
    "print(fg_result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extract-coefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and display coefficients\n",
    "coef_df = pd.DataFrame({\n",
    "    'feature': ['intercept'] + feature_cols,\n",
    "    'coefficient': fg_result.params,\n",
    "    'std_err': fg_result.bse,\n",
    "    'z': fg_result.tvalues,\n",
    "    'p_value': fg_result.pvalues,\n",
    "    'hazard_ratio': np.exp(fg_result.params),\n",
    "})\n",
    "\n",
    "# Add confidence intervals\n",
    "conf_int = fg_result.conf_int()\n",
    "coef_df['ci_lower'] = np.exp(conf_int[0])\n",
    "coef_df['ci_upper'] = np.exp(conf_int[1])\n",
    "\n",
    "print(\"\\n=== Fine-Gray Coefficients (Standardized) ===\")\n",
    "print(coef_df.round(4).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-coefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot hazard ratios with confidence intervals\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Skip intercept\n",
    "plot_df = coef_df[coef_df['feature'] != 'intercept'].copy()\n",
    "\n",
    "y_pos = np.arange(len(plot_df))\n",
    "colors = ['green' if c < 0 else 'red' for c in plot_df['coefficient']]\n",
    "\n",
    "ax.barh(y_pos, plot_df['hazard_ratio'], color=colors, alpha=0.7)\n",
    "ax.errorbar(plot_df['hazard_ratio'], y_pos, \n",
    "            xerr=[plot_df['hazard_ratio'] - plot_df['ci_lower'],\n",
    "                  plot_df['ci_upper'] - plot_df['hazard_ratio']],\n",
    "            fmt='none', color='black', capsize=3)\n",
    "\n",
    "ax.axvline(x=1, color='black', linestyle='--', linewidth=1)\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(plot_df['feature'])\n",
    "ax.set_xlabel('Hazard Ratio (95% CI)')\n",
    "ax.set_title('Fine-Gray Model: Prepayment Subdistribution Hazard Ratios')\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/fine_gray_hazard_ratios.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate-header",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, brier_score_loss, log_loss\n",
    "\n",
    "# Predict probabilities\n",
    "y_pred_train = fg_model.predict_proba(X_train)[:, 1]\n",
    "y_pred_test = fg_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculate metrics\n",
    "print(\"=== Model Evaluation ===\")\n",
    "print(f\"\\nTraining Set:\")\n",
    "print(f\"  AUC: {roc_auc_score(y_train, y_pred_train):.4f}\")\n",
    "print(f\"  Brier Score: {brier_score_loss(y_train, y_pred_train):.4f}\")\n",
    "print(f\"  Log Loss: {log_loss(y_train, y_pred_train):.4f}\")\n",
    "\n",
    "print(f\"\\nTest Set:\")\n",
    "print(f\"  AUC: {roc_auc_score(y_test, y_pred_test):.4f}\")\n",
    "print(f\"  Brier Score: {brier_score_loss(y_test, y_pred_test):.4f}\")\n",
    "print(f\"  Log Loss: {log_loss(y_test, y_pred_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "calibration-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration plot\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "prob_true, prob_pred = calibration_curve(y_test, y_pred_test, n_bins=10)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', label='Perfect calibration')\n",
    "ax.plot(prob_pred, prob_true, 'o-', label='Fine-Gray model')\n",
    "\n",
    "ax.set_xlabel('Mean predicted probability')\n",
    "ax.set_ylabel('Fraction of positives')\n",
    "ax.set_title('Calibration Plot: Fine-Gray Prepayment Model')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../reports/figures/fine_gray_calibration.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cif-prediction-header",
   "metadata": {},
   "source": [
    "## Cumulative Incidence Prediction\n",
    "\n",
    "For discrete-time models:\n",
    "$$CIF(t) = \\sum_{s \\leq t} h(s) \\cdot S(s-1)$$\n",
    "\n",
    "where $h(s)$ is the subdistribution hazard and $S(s)$ is survival."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cif-prediction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cif_simple(hazard_probs: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Convert hazard probabilities to cumulative incidence.\n",
    "    \n",
    "    For a single subject's hazard over time:\n",
    "    CIF(t) = 1 - prod(1 - h(s)) for s = 1 to t\n",
    "    \"\"\"\n",
    "    survival = np.cumprod(1 - hazard_probs)\n",
    "    cif = 1 - survival\n",
    "    return cif\n",
    "\n",
    "# For illustration, show CIF for representative profiles\n",
    "print(\"Predicted subdistribution hazard (first 10 records):\")\n",
    "print(y_pred_test[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "MODELS_DIR = Path('../models')\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Save sklearn model\n",
    "with open(MODELS_DIR / 'fine_gray_prepay.pkl', 'wb') as f:\n",
    "    pickle.dump({'model': fg_model, 'scaler': scaler, 'features': feature_cols}, f)\n",
    "\n",
    "# Save statsmodels result\n",
    "fg_result.save(MODELS_DIR / 'fine_gray_prepay_sm.pkl')\n",
    "\n",
    "print(f\"Models saved to {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\" * 60)\nprint(\"FINE-GRAY MODEL SUMMARY\")\nprint(\"=\" * 60)\n\nprint(f\"\\nModel: Discrete-time Fine-Gray (Logistic Regression)\")\nprint(f\"Primary Event: Prepayment (event=1)\")\nprint(f\"Competing Event: Default (event=2)\")\n\nprint(f\"\\nFeatures (Blumenstock et al. 2022):\")\nprint(f\"  Static: {len([f for f in STATIC_FEATURES if f in feature_cols or 'log_upb' in feature_cols])}/5\")\nprint(f\"  Behavioral: {len([f for f in BEHAVIORAL_FEATURES if f in feature_cols])}/4\")\nprint(f\"  Macro: {len([f for f in MACRO_FEATURES if f in feature_cols])}/12\")\nprint(f\"  Total: {len(feature_cols)}/21\")\n\nprint(f\"\\nPerformance:\")\nprint(f\"  Test AUC: {roc_auc_score(y_test, y_pred_test):.4f}\")\nprint(f\"  Test Brier Score: {brier_score_loss(y_test, y_pred_test):.4f}\")\n\nprint(f\"\\nKey Coefficients (significant at p<0.05):\")\nsig_coefs = coef_df[(coef_df['p_value'] < 0.05) & (coef_df['feature'] != 'intercept')]\nfor _, row in sig_coefs.iterrows():\n    direction = '↑' if row['coefficient'] > 0 else '↓'\n    print(f\"  {row['feature']}: HR={row['hazard_ratio']:.3f} {direction}\")"
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "**Notebook 07**: Compare Fine-Gray vs Cause-Specific Cox models\n",
    "\n",
    "Key comparisons:\n",
    "- Coefficient differences and interpretations\n",
    "- Discrimination metrics (C-index, time-dependent AUC)\n",
    "- Cumulative incidence predictions vs observed\n",
    "- Calibration assessment"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}