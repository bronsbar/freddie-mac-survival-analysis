{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Random Survival Forest for Competing Risks\n",
    "\n",
    "This notebook implements **Random Survival Forest (RSF)** for competing risks following Ishwaran et al. (2014). RSF is a non-parametric ensemble method that can capture non-linear effects and interactions.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "| Aspect | Description |\n",
    "|--------|-------------|\n",
    "| **Model** | Cause-specific RSF (separate model per event) |\n",
    "| **Base** | scikit-survival RandomSurvivalForest |\n",
    "| **Features** | Blumenstock et al. (2022) - 21 variables |\n",
    "| **Evaluation** | Time-dependent C-index at 24, 48, 72 months |\n",
    "\n",
    "## Comparison to Parametric Models\n",
    "\n",
    "| Model | Assumptions | Interpretability | Flexibility |\n",
    "|-------|-------------|------------------|-------------|\n",
    "| Cox PH | Proportional hazards | High (coefficients) | Low |\n",
    "| Fine-Gray | Subdistribution PH | High (coefficients) | Low |\n",
    "| **RSF** | None | Medium (importance) | High |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Survival analysis\n",
    "from sksurv.ensemble import RandomSurvivalForest\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import concordance_index_censored, concordance_index_ipcw\n",
    "\n",
    "# Custom module\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from src.competing_risks.random_forest import CompetingRisksRSF, fit_rsf_competing_risks\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Time horizons for evaluation (matching notebooks 05 and 06)\n",
    "TIME_HORIZONS = [24, 48, 72]\n",
    "\n",
    "print(\"Imports complete.\")\n",
    "print(f\"Time horizons for C-index evaluation: {TIME_HORIZONS} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "DATA_DIR = Path('../data/processed')\n",
    "FIGURES_DIR = Path('../reports/figures')\n",
    "MODELS_DIR = Path('../models')\n",
    "\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cross-validation folds (Blumenstock methodology)\n",
    "TRAIN_FOLDS = list(range(10))  # Folds 0-9 for training\n",
    "TEST_FOLD = 10                  # Fold 10 for testing\n",
    "\n",
    "# RSF hyperparameters\n",
    "RSF_PARAMS = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 10,\n",
    "    'min_samples_split': 20,\n",
    "    'min_samples_leaf': 10,\n",
    "    'max_features': 'sqrt',\n",
    "    'n_jobs': -1,\n",
    "    'random_state': 42,\n",
    "}\n",
    "\n",
    "print(f\"Training folds: {TRAIN_FOLDS}\")\n",
    "print(f\"Test fold: {TEST_FOLD}\")\n",
    "print(f\"\\nRSF parameters: {RSF_PARAMS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load Loan-Month Panel Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loan-month panel data\n",
    "print(\"Loading loan-month panel data...\")\n",
    "panel_df = pd.read_parquet(DATA_DIR / 'loan_month_panel.parquet')\n",
    "\n",
    "print(f\"Loaded {len(panel_df):,} loan-months\")\n",
    "print(f\"Unique loans: {panel_df['loan_sequence_number'].nunique():,}\")\n",
    "print(f\"Folds: {sorted(panel_df['fold'].unique())}\")\n",
    "print(f\"Vintages: {panel_df['vintage_year'].min()} - {panel_df['vintage_year'].max()}\")\n",
    "\n",
    "print(\"\\nEvent distribution (terminal observations):\")\n",
    "event_names = {0: 'Censored', 1: 'Prepay', 2: 'Default'}\n",
    "terminal_events = panel_df[panel_df['event'] == 1].groupby('event_code').size()\n",
    "for code, count in terminal_events.items():\n",
    "    print(f\"  {event_names.get(code, 'Other')} (k={code}): {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "features-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Define Features (Blumenstock et al. 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature groups (Blumenstock et al. 2022, Table 2)\n",
    "# Matching notebooks 05 and 06 exactly\n",
    "\n",
    "# Static covariates (fixed at origination) - 5 variables\n",
    "STATIC_FEATURES = [\n",
    "    'int_rate',      # Initial interest rate\n",
    "    'orig_upb',      # Original unpaid balance\n",
    "    'fico_score',    # Initial FICO score\n",
    "    'dti_r',         # Initial debt-to-income ratio\n",
    "    'ltv_r',         # Initial loan-to-value ratio\n",
    "]\n",
    "\n",
    "# Behavioral covariates (time-varying) - 4 variables\n",
    "BEHAVIORAL_FEATURES = [\n",
    "    'bal_repaid',      # Current repaid balance in percent\n",
    "    't_act_12m',       # No. of times not being delinquent in last 12 months\n",
    "    't_del_30d_12m',   # No. of times being 30 days delinquent in last 12 months\n",
    "    't_del_60d_12m',   # No. of times being 60 days delinquent in last 12 months\n",
    "]\n",
    "\n",
    "# Macro covariates (time-varying) - 12 variables\n",
    "MACRO_FEATURES = [\n",
    "    'hpi_st_d_t_o',    # HPI difference between origination and today (state)\n",
    "    'ppi_c_FRMA',      # Current prepayment incentive\n",
    "    'TB10Y_d_t_o',     # Treasury rate difference\n",
    "    'FRMA30Y_d_t_o',   # 30Y FRM difference\n",
    "    'ppi_o_FRMA',      # Prepayment incentive at origination\n",
    "    'hpi_st_log12m',   # HPI 12-month log return (state)\n",
    "    'hpi_r_st_us',     # Ratio of state HPI to national HPI\n",
    "    'st_unemp_r12m',   # Unemployment 12-month log return (state)\n",
    "    'st_unemp_r3m',    # Unemployment 3-month log return (state)\n",
    "    'TB10Y_r12m',      # Treasury rate 12-month return\n",
    "    'T10Y3MM',         # Yield spread (10Y - 3M)\n",
    "    'T10Y3MM_r12m',    # Yield spread 12-month return\n",
    "]\n",
    "\n",
    "ALL_FEATURES = STATIC_FEATURES + BEHAVIORAL_FEATURES + MACRO_FEATURES\n",
    "\n",
    "# Filter to available features\n",
    "feature_cols = [f for f in ALL_FEATURES if f in panel_df.columns]\n",
    "missing_features = [f for f in ALL_FEATURES if f not in panel_df.columns]\n",
    "\n",
    "print(\"=== Feature Groups (Blumenstock et al. 2022) ===\")\n",
    "print(f\"Static features: {len([f for f in STATIC_FEATURES if f in feature_cols])}/5\")\n",
    "print(f\"Behavioral features: {len([f for f in BEHAVIORAL_FEATURES if f in feature_cols])}/4\")\n",
    "print(f\"Macro features: {len([f for f in MACRO_FEATURES if f in feature_cols])}/12\")\n",
    "print(f\"\\nTotal available: {len(feature_cols)}/21\")\n",
    "\n",
    "if missing_features:\n",
    "    print(f\"\\nMissing features ({len(missing_features)}):\")\n",
    "    for f in missing_features:\n",
    "        print(f\"  - {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Prepare Data for RSF\n",
    "\n",
    "RSF requires terminal observations (one per loan) rather than the full panel. We use the last observation for each loan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For RSF, we need terminal observations (one per loan)\n",
    "# Get the last observation for each loan\n",
    "print(\"=== Preparing Terminal Observations ===\")\n",
    "\n",
    "time_col = 'loan_age'\n",
    "event_col = 'event_code'\n",
    "\n",
    "# Sort and get last observation per loan\n",
    "panel_df = panel_df.sort_values(['loan_sequence_number', time_col])\n",
    "terminal_df = panel_df.groupby('loan_sequence_number').last().reset_index()\n",
    "\n",
    "print(f\"Terminal observations: {len(terminal_df):,} loans\")\n",
    "\n",
    "# Lag bal_repaid to avoid data leakage (matching notebook 06)\n",
    "# At prepayment, bal_repaid=100% by definition\n",
    "# Use the second-to-last observation's bal_repaid\n",
    "if 'bal_repaid' in feature_cols:\n",
    "    print(\"\\nLagging bal_repaid to avoid data leakage...\")\n",
    "    \n",
    "    # Get second-to-last observation for bal_repaid\n",
    "    def get_lagged_bal_repaid(group):\n",
    "        if len(group) >= 2:\n",
    "            return group['bal_repaid'].iloc[-2]\n",
    "        else:\n",
    "            return group['bal_repaid'].iloc[-1]\n",
    "    \n",
    "    bal_repaid_lag = panel_df.groupby('loan_sequence_number').apply(get_lagged_bal_repaid)\n",
    "    terminal_df['bal_repaid_lag1'] = terminal_df['loan_sequence_number'].map(bal_repaid_lag)\n",
    "    \n",
    "    # Replace bal_repaid with lagged version\n",
    "    feature_cols = [f if f != 'bal_repaid' else 'bal_repaid_lag1' for f in feature_cols]\n",
    "    print(\"✓ Created bal_repaid_lag1\")\n",
    "\n",
    "# Log transform UPB\n",
    "if 'orig_upb' in terminal_df.columns:\n",
    "    terminal_df['log_upb'] = np.log(terminal_df['orig_upb'])\n",
    "    feature_cols = [f if f != 'orig_upb' else 'log_upb' for f in feature_cols]\n",
    "    print(\"✓ Created log_upb\")\n",
    "\n",
    "# Drop rows with missing features\n",
    "n_before = len(terminal_df)\n",
    "terminal_df = terminal_df.dropna(subset=feature_cols)\n",
    "n_after = len(terminal_df)\n",
    "print(f\"\\nAfter dropping NaN: {n_after:,} loans (dropped {n_before - n_after:,})\")\n",
    "\n",
    "print(f\"\\nFeatures ({len(feature_cols)}): {feature_cols}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by folds (matching notebooks 05 and 06)\n",
    "print(\"=== Splitting Data by Folds ===\")\n",
    "\n",
    "train_df = terminal_df[terminal_df['fold'].isin(TRAIN_FOLDS)].copy()\n",
    "test_df = terminal_df[terminal_df['fold'] == TEST_FOLD].copy()\n",
    "\n",
    "print(f\"Training set (folds 0-9): {len(train_df):,} loans\")\n",
    "print(f\"Test set (fold 10): {len(test_df):,} loans\")\n",
    "\n",
    "# Event distribution\n",
    "print(\"\\nTraining set event distribution:\")\n",
    "for code, name in event_names.items():\n",
    "    count = (train_df[event_col] == code).sum()\n",
    "    print(f\"  {name}: {count:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fit-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Fit Random Survival Forest\n",
    "\n",
    "We fit cause-specific RSF models for prepayment and default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-prepay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit RSF for PREPAYMENT (event=1)\n",
    "print(\"=== Fitting RSF for PREPAYMENT ===\")\n",
    "\n",
    "# Prepare data\n",
    "X_train = train_df[feature_cols].values\n",
    "X_test = test_df[feature_cols].values\n",
    "\n",
    "# Create cause-specific event indicator (prepay=True, others=False)\n",
    "event_prepay_train = (train_df[event_col] == 1).values\n",
    "event_prepay_test = (test_df[event_col] == 1).values\n",
    "\n",
    "duration_train = train_df[time_col].values\n",
    "duration_test = test_df[time_col].values\n",
    "\n",
    "# Create structured array for scikit-survival\n",
    "y_train_prepay = Surv.from_arrays(event_prepay_train, duration_train)\n",
    "y_test_prepay = Surv.from_arrays(event_prepay_test, duration_test)\n",
    "\n",
    "# Fit RSF\n",
    "rsf_prepay = RandomSurvivalForest(**RSF_PARAMS)\n",
    "rsf_prepay.fit(X_train, y_train_prepay)\n",
    "\n",
    "print(f\"\\n✓ RSF Prepayment model fitted\")\n",
    "print(f\"  Trees: {rsf_prepay.n_estimators}\")\n",
    "print(f\"  Max depth: {rsf_prepay.max_depth}\")\n",
    "print(f\"  Training events: {event_prepay_train.sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fit-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit RSF for DEFAULT (event=2)\n",
    "print(\"=== Fitting RSF for DEFAULT ===\")\n",
    "\n",
    "# Create cause-specific event indicator (default=True, others=False)\n",
    "event_default_train = (train_df[event_col] == 2).values\n",
    "event_default_test = (test_df[event_col] == 2).values\n",
    "\n",
    "# Create structured array\n",
    "y_train_default = Surv.from_arrays(event_default_train, duration_train)\n",
    "y_test_default = Surv.from_arrays(event_default_test, duration_test)\n",
    "\n",
    "# Fit RSF\n",
    "rsf_default = RandomSurvivalForest(**RSF_PARAMS)\n",
    "rsf_default.fit(X_train, y_train_default)\n",
    "\n",
    "print(f\"\\n✓ RSF Default model fitted\")\n",
    "print(f\"  Trees: {rsf_default.n_estimators}\")\n",
    "print(f\"  Max depth: {rsf_default.max_depth}\")\n",
    "print(f\"  Training events: {event_default_train.sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluate-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "Evaluate using time-dependent C-index at 24, 48, and 72 months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate-prepay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate PREPAYMENT model\n",
    "print(\"=== RSF Prepayment Model Evaluation ===\")\n",
    "\n",
    "# Get risk scores (higher = more risk of prepayment)\n",
    "risk_prepay_train = rsf_prepay.predict(X_train)\n",
    "risk_prepay_test = rsf_prepay.predict(X_test)\n",
    "\n",
    "# Time-dependent C-index\n",
    "print(\"\\nTime-Dependent C-index (IPCW) for PREPAYMENT:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "cindex_prepay_results = {}\n",
    "for tau in TIME_HORIZONS:\n",
    "    try:\n",
    "        c_tau = concordance_index_ipcw(\n",
    "            y_train_prepay,\n",
    "            y_test_prepay,\n",
    "            risk_prepay_test,\n",
    "            tau=tau\n",
    "        )\n",
    "        cindex_prepay_results[tau] = c_tau[0]\n",
    "        print(f\"  τ = {tau:3d} months: C-index = {c_tau[0]:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  τ = {tau:3d} months: Error - {str(e)[:50]}\")\n",
    "\n",
    "# Overall C-index (Harrell's)\n",
    "c_index_prepay = concordance_index_censored(\n",
    "    event_prepay_test,\n",
    "    duration_test,\n",
    "    risk_prepay_test\n",
    ")\n",
    "print(f\"\\nOverall C-index (Harrell): {c_index_prepay[0]:.4f}\")\n",
    "print(f\"  Concordant: {c_index_prepay[1]:,} | Discordant: {c_index_prepay[2]:,} | Tied: {c_index_prepay[3]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate-default",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate DEFAULT model\n",
    "print(\"=== RSF Default Model Evaluation ===\")\n",
    "\n",
    "# Get risk scores\n",
    "risk_default_train = rsf_default.predict(X_train)\n",
    "risk_default_test = rsf_default.predict(X_test)\n",
    "\n",
    "# Time-dependent C-index\n",
    "print(\"\\nTime-Dependent C-index (IPCW) for DEFAULT:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "cindex_default_results = {}\n",
    "for tau in TIME_HORIZONS:\n",
    "    try:\n",
    "        c_tau = concordance_index_ipcw(\n",
    "            y_train_default,\n",
    "            y_test_default,\n",
    "            risk_default_test,\n",
    "            tau=tau\n",
    "        )\n",
    "        cindex_default_results[tau] = c_tau[0]\n",
    "        print(f\"  τ = {tau:3d} months: C-index = {c_tau[0]:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"  τ = {tau:3d} months: Error - {str(e)[:50]}\")\n",
    "\n",
    "# Overall C-index (Harrell's)\n",
    "c_index_default = concordance_index_censored(\n",
    "    event_default_test,\n",
    "    duration_test,\n",
    "    risk_default_test\n",
    ")\n",
    "print(f\"\\nOverall C-index (Harrell): {c_index_default[0]:.4f}\")\n",
    "print(f\"  Concordant: {c_index_default[1]:,} | Discordant: {c_index_default[2]:,} | Tied: {c_index_default[3]:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-cindex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time-dependent C-index comparison\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Prepare data for plotting\n",
    "horizons = sorted(set(cindex_prepay_results.keys()) & set(cindex_default_results.keys()))\n",
    "prepay_cindex = [cindex_prepay_results[h] for h in horizons]\n",
    "default_cindex = [cindex_default_results[h] for h in horizons]\n",
    "\n",
    "x = np.arange(len(horizons))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, prepay_cindex, width, label='Prepayment', color='steelblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, default_cindex, width, label='Default', color='indianred', alpha=0.8)\n",
    "\n",
    "# Add value labels\n",
    "for bar, val in zip(bars1, prepay_cindex):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "for bar, val in zip(bars2, default_cindex):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "            f'{val:.3f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', alpha=0.5, label='Random (0.5)')\n",
    "\n",
    "ax.set_xlabel('Time Horizon (months)', fontsize=12)\n",
    "ax.set_ylabel('C-index (IPCW)', fontsize=12)\n",
    "ax.set_title('RSF: Time-Dependent Concordance Index by Event Type', fontsize=14)\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels([f'τ = {h}' for h in horizons])\n",
    "ax.set_ylim(0.4, 1.0)\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'rsf_time_dependent_cindex.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Figure saved to: {FIGURES_DIR / 'rsf_time_dependent_cindex.png'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "importance-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Feature Importance\n",
    "\n",
    "RSF provides permutation-based feature importance scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "print(\"=== Feature Importance ===\")\n",
    "\n",
    "# Prepayment model\n",
    "importance_prepay = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rsf_prepay.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Default model\n",
    "importance_default = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': rsf_default.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 Features - PREPAYMENT:\")\n",
    "print(importance_prepay.head(10).to_string(index=False))\n",
    "\n",
    "print(\"\\nTop 10 Features - DEFAULT:\")\n",
    "print(importance_default.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "# Prepayment\n",
    "ax = axes[0]\n",
    "top_n = 15\n",
    "plot_df = importance_prepay.head(top_n).iloc[::-1]  # Reverse for horizontal bar\n",
    "ax.barh(plot_df['feature'], plot_df['importance'], color='steelblue', alpha=0.7)\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('RSF Feature Importance: Prepayment', fontsize=12)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Default\n",
    "ax = axes[1]\n",
    "plot_df = importance_default.head(top_n).iloc[::-1]\n",
    "ax.barh(plot_df['feature'], plot_df['importance'], color='indianred', alpha=0.7)\n",
    "ax.set_xlabel('Importance')\n",
    "ax.set_title('RSF Feature Importance: Default', fontsize=12)\n",
    "ax.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'rsf_feature_importance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-models",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models\n",
    "with open(MODELS_DIR / 'rsf_prepay.pkl', 'wb') as f:\n",
    "    pickle.dump(rsf_prepay, f)\n",
    "\n",
    "with open(MODELS_DIR / 'rsf_default.pkl', 'wb') as f:\n",
    "    pickle.dump(rsf_default, f)\n",
    "\n",
    "# Save feature importance\n",
    "importance_prepay.to_csv(MODELS_DIR / 'rsf_importance_prepay.csv', index=False)\n",
    "importance_default.to_csv(MODELS_DIR / 'rsf_importance_default.csv', index=False)\n",
    "\n",
    "print(f\"Models saved to {MODELS_DIR}:\")\n",
    "print(f\"  - rsf_prepay.pkl\")\n",
    "print(f\"  - rsf_default.pkl\")\n",
    "print(f\"  - rsf_importance_prepay.csv\")\n",
    "print(f\"  - rsf_importance_default.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"RANDOM SURVIVAL FOREST - SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nData:\")\n",
    "print(f\"  Training loans: {len(train_df):,}\")\n",
    "print(f\"  Test loans: {len(test_df):,}\")\n",
    "\n",
    "print(f\"\\nFeatures: {len(feature_cols)}\")\n",
    "print(f\"  Static: {len([f for f in STATIC_FEATURES if f in feature_cols or 'log_upb' in feature_cols])}\")\n",
    "print(f\"  Behavioral: {len([f for f in BEHAVIORAL_FEATURES if f in feature_cols or 'bal_repaid_lag1' in feature_cols])}\")\n",
    "print(f\"  Macro: {len([f for f in MACRO_FEATURES if f in feature_cols])}\")\n",
    "\n",
    "print(f\"\\nRSF Parameters:\")\n",
    "for param, value in RSF_PARAMS.items():\n",
    "    print(f\"  {param}: {value}\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"MODEL PERFORMANCE (Test Set)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nPREPAYMENT MODEL:\")\n",
    "print(f\"  Training events: {event_prepay_train.sum():,}\")\n",
    "print(f\"  Overall C-index (Harrell): {c_index_prepay[0]:.4f}\")\n",
    "print(f\"  Time-Dependent C-index (IPCW):\")\n",
    "for tau, c in cindex_prepay_results.items():\n",
    "    print(f\"    τ = {tau:3d} months: {c:.4f}\")\n",
    "\n",
    "print(f\"\\nDEFAULT MODEL:\")\n",
    "print(f\"  Training events: {event_default_train.sum():,}\")\n",
    "print(f\"  Overall C-index (Harrell): {c_index_default[0]:.4f}\")\n",
    "print(f\"  Time-Dependent C-index (IPCW):\")\n",
    "for tau, c in cindex_default_results.items():\n",
    "    print(f\"    τ = {tau:3d} months: {c:.4f}\")\n",
    "\n",
    "print(f\"\\nTop 3 Important Features:\")\n",
    "print(f\"  Prepayment: {', '.join(importance_prepay['feature'].head(3).tolist())}\")\n",
    "print(f\"  Default: {', '.join(importance_default['feature'].head(3).tolist())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "next-steps",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "**Notebook 08**: Model Comparison\n",
    "\n",
    "Compare all models:\n",
    "- Cause-Specific Cox (notebook 05)\n",
    "- Fine-Gray (notebook 06)\n",
    "- Random Survival Forest (this notebook)\n",
    "\n",
    "Key comparisons:\n",
    "- Time-dependent C-index at multiple horizons\n",
    "- Calibration assessment\n",
    "- Cumulative incidence predictions\n",
    "- Computational cost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
