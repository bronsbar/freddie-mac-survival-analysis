{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# Bayesian Competing Risks Model\n",
    "\n",
    "This notebook implements the **Bayesian competing risks proportional hazards model** from Bhattacharya, Wilson & Soyer (2019) for mortgage default and prepayment prediction.\n",
    "\n",
    "## Methodology\n",
    "\n",
    "| Aspect | Description |\n",
    "|--------|-------------|\n",
    "| **Model** | Bayesian competing risks PHM with lognormal baseline hazards |\n",
    "| **Inference** | MCMC via Pyro/NUTS (PyTorch-based) |\n",
    "| **Features** | Loan characteristics (matching Blumenstock et al. 2022) |\n",
    "| **Evaluation** | Time-dependent C-index at 24, 48, 72 months |\n",
    "\n",
    "## Key Advantages of Bayesian Approach\n",
    "\n",
    "| Feature | Description |\n",
    "|---------|-------------|\n",
    "| **Full uncertainty quantification** | Posterior distributions for all parameters |\n",
    "| **Probabilistic predictions** | Credible intervals for survival/CIF |\n",
    "| **Prior information** | Can incorporate domain knowledge |\n",
    "| **Coherent inference** | Natural handling of small samples |\n",
    "\n",
    "## Model Specification\n",
    "\n",
    "**Default hazard:**\n",
    "$$\\lambda_D(t | X) = r_D(t | \\mu_D, \\sigma_D) \\exp(\\theta_D' X)$$\n",
    "\n",
    "**Prepayment hazard:**\n",
    "$$\\lambda_P(t | X) = r_P(t | \\mu_P, \\sigma_P) \\exp(\\theta_P' X)$$\n",
    "\n",
    "where $r(t | \\mu, \\sigma)$ is the lognormal baseline hazard.\n",
    "\n",
    "## References\n",
    "\n",
    "- Bhattacharya, A., Wilson, S.P., & Soyer, R. (2019). A Bayesian approach to modeling mortgage default and prepayment. *European Journal of Operational Research*, 274, 1112-1124."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Bayesian inference (Pyro - PyTorch based)\n",
    "import torch\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC, NUTS\n",
    "import arviz as az\n",
    "\n",
    "# Survival analysis metrics\n",
    "from sksurv.util import Surv\n",
    "from sksurv.metrics import concordance_index_censored, concordance_index_ipcw\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "\n",
    "# Import our Bayesian evaluation module\n",
    "import sys\n",
    "sys.path.insert(0, '../src')\n",
    "from competing_risks.bayesian_evaluation import (\n",
    "    compute_time_dependent_cindex,\n",
    "    compute_brier_score,\n",
    "    compute_calibration,\n",
    "    compute_coverage_probability,\n",
    "    evaluate_bayesian_model,\n",
    "    format_evaluation_results,\n",
    ")\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "pyro.set_rng_seed(42)\n",
    "\n",
    "# Time horizons for evaluation (matching previous notebooks)\n",
    "TIME_HORIZONS = [24, 48, 72]\n",
    "\n",
    "# Device selection\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = 'cuda'\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = 'mps'\n",
    "else:\n",
    "    DEVICE = 'cpu'\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Pyro version: {pyro.__version__}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Time horizons for C-index evaluation: {TIME_HORIZONS} months\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CONFIGURATION ===\n",
    "DATA_DIR = Path('../data/processed')\n",
    "FIGURES_DIR = Path('../reports/figures')\n",
    "MODELS_DIR = Path('../models')\n",
    "\n",
    "FIGURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cross-validation folds (Blumenstock methodology)\n",
    "TRAIN_FOLDS = list(range(9))   # Folds 0-8 for training\n",
    "VAL_FOLDS = [9]                 # Fold 9 for validation\n",
    "TEST_FOLD = 10                  # Fold 10 for testing\n",
    "\n",
    "# MCMC settings\n",
    "MCMC_PARAMS = {\n",
    "    'num_warmup': 1000,\n",
    "    'num_samples': 2000,\n",
    "    'num_chains': 4,\n",
    "    'target_accept_prob': 0.8,\n",
    "}\n",
    "\n",
    "# Prior hyperparameters (from Bhattacharya et al. 2018)\n",
    "PRIOR_PARAMS = {\n",
    "    'theta_sd': 100.0,      # SD for regression coefficient priors\n",
    "    'mu_sd': 10.0,          # SD for baseline mean priors\n",
    "    'sigma_rate': 0.01,     # Rate for exponential prior on sigma (mean=100)\n",
    "}\n",
    "\n",
    "print(f\"Training folds: {TRAIN_FOLDS}\")\n",
    "print(f\"Validation fold: {VAL_FOLDS}\")\n",
    "print(f\"Test fold: {TEST_FOLD}\")\n",
    "print(f\"\\nMCMC parameters:\")\n",
    "for k, v in MCMC_PARAMS.items():\n",
    "    print(f\"  {k}: {v}\")\n",
    "print(f\"\\nPrior parameters:\")\n",
    "for k, v in PRIOR_PARAMS.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load-data-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the loan-month panel data\n",
    "print(\"Loading loan-month panel data...\")\n",
    "panel_df = pd.read_parquet(DATA_DIR / 'loan_month_panel.parquet')\n",
    "\n",
    "print(f\"Loaded {len(panel_df):,} loan-months\")\n",
    "print(f\"Unique loans: {panel_df['loan_sequence_number'].nunique():,}\")\n",
    "print(f\"Folds: {sorted(panel_df['fold'].unique())}\")\n",
    "print(f\"Vintages: {panel_df['vintage_year'].min()} - {panel_df['vintage_year'].max()}\")\n",
    "\n",
    "print(\"\\nEvent distribution (terminal observations):\")\n",
    "event_names = {0: 'Censored', 1: 'Prepay', 2: 'Default'}\n",
    "terminal_events = panel_df[panel_df['event'] == 1].groupby('event_code').size()\n",
    "for code, count in terminal_events.items():\n",
    "    print(f\"  {event_names.get(code, 'Other')} (k={code}): {count:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "define-features",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature groups\n",
    "STATIC_FEATURES = ['int_rate', 'orig_upb', 'fico_score', 'dti_r', 'ltv_r']\n",
    "BEHAVIORAL_FEATURES = ['bal_repaid', 't_act_12m', 't_del_30d_12m', 't_del_60d_12m']\n",
    "MACRO_FEATURES = ['hpi_st_d_t_o', 'ppi_c_FRMA', 'TB10Y_d_t_o', 'FRMA30Y_d_t_o']\n",
    "\n",
    "ALL_FEATURES = STATIC_FEATURES + BEHAVIORAL_FEATURES + MACRO_FEATURES\n",
    "feature_cols = [f for f in ALL_FEATURES if f in panel_df.columns]\n",
    "print(f\"Available features: {len(feature_cols)}/{len(ALL_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare terminal observations\n",
    "time_col, event_col = 'loan_age', 'event_code'\n",
    "panel_df = panel_df.sort_values(['loan_sequence_number', time_col])\n",
    "terminal_df = panel_df.groupby('loan_sequence_number').last().reset_index()\n",
    "\n",
    "# Feature engineering\n",
    "if 'bal_repaid' in feature_cols:\n",
    "    bal_repaid_lag = panel_df.groupby('loan_sequence_number').apply(\n",
    "        lambda g: g['bal_repaid'].iloc[-2] if len(g) >= 2 else g['bal_repaid'].iloc[-1])\n",
    "    terminal_df['bal_repaid_lag1'] = terminal_df['loan_sequence_number'].map(bal_repaid_lag)\n",
    "    feature_cols = [f if f != 'bal_repaid' else 'bal_repaid_lag1' for f in feature_cols]\n",
    "\n",
    "if 'orig_upb' in terminal_df.columns:\n",
    "    terminal_df['log_upb'] = np.log(terminal_df['orig_upb'])\n",
    "    feature_cols = [f if f != 'orig_upb' else 'log_upb' for f in feature_cols]\n",
    "\n",
    "terminal_df = terminal_df.dropna(subset=feature_cols)\n",
    "print(f\"Terminal observations: {len(terminal_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df = terminal_df[terminal_df['fold'].isin(TRAIN_FOLDS)].copy()\n",
    "val_df = terminal_df[terminal_df['fold'].isin(VAL_FOLDS)].copy()\n",
    "test_df = terminal_df[terminal_df['fold'] == TEST_FOLD].copy()\n",
    "\n",
    "print(f\"Train: {len(train_df):,}, Val: {len(val_df):,}, Test: {len(test_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preprocess",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(train_df[feature_cols]).astype('float32')\n",
    "X_val = scaler.transform(val_df[feature_cols]).astype('float32')\n",
    "X_test = scaler.transform(test_df[feature_cols]).astype('float32')\n",
    "\n",
    "duration_train = np.maximum(train_df[time_col].values.astype('float32'), 0.5)\n",
    "duration_val = np.maximum(val_df[time_col].values.astype('float32'), 0.5)\n",
    "duration_test = np.maximum(test_df[time_col].values.astype('float32'), 0.5)\n",
    "\n",
    "event_train = train_df[event_col].values.astype('int32')\n",
    "event_val = val_df[event_col].values.astype('int32')\n",
    "event_test = test_df[event_col].values.astype('int32')\n",
    "\n",
    "print(f\"X_train: {X_train.shape}, Duration range: {duration_train.min():.1f}-{duration_train.max():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Bayesian Competing Risks Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-functions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lognormal hazard functions\n",
    "def lognormal_log_hazard(t, mu, sigma):\n",
    "    z = (torch.log(t) - mu) / sigma\n",
    "    log_phi = -0.5 * z**2 - 0.5 * torch.log(torch.tensor(2 * np.pi, device=t.device))\n",
    "    Phi_z = 0.5 * (1 + torch.erf(z / np.sqrt(2)))\n",
    "    log_survival = torch.log(1 - Phi_z + 1e-10)\n",
    "    return log_phi - torch.log(sigma) - torch.log(t) - log_survival\n",
    "\n",
    "def lognormal_cumulative_hazard(t, mu, sigma):\n",
    "    z = (torch.log(t) - mu) / sigma\n",
    "    Phi_z = 0.5 * (1 + torch.erf(z / np.sqrt(2)))\n",
    "    return -torch.log(1 - Phi_z + 1e-10)\n",
    "\n",
    "print(\"Hazard functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pyro-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyro model\n",
    "def bayesian_competing_risks_model(X, durations, events, n_features):\n",
    "    device = X.device\n",
    "    \n",
    "    # Priors\n",
    "    mu_D = pyro.sample('mu_D', dist.Normal(3.0, PRIOR_PARAMS['mu_sd']))\n",
    "    sigma_D = pyro.sample('sigma_D', dist.Exponential(PRIOR_PARAMS['sigma_rate']))\n",
    "    mu_P = pyro.sample('mu_P', dist.Normal(3.0, PRIOR_PARAMS['mu_sd']))\n",
    "    sigma_P = pyro.sample('sigma_P', dist.Exponential(PRIOR_PARAMS['sigma_rate']))\n",
    "    \n",
    "    theta_D = pyro.sample('theta_D', dist.Normal(\n",
    "        torch.zeros(n_features, device=device),\n",
    "        PRIOR_PARAMS['theta_sd'] * torch.ones(n_features, device=device)).to_event(1))\n",
    "    theta_P = pyro.sample('theta_P', dist.Normal(\n",
    "        torch.zeros(n_features, device=device),\n",
    "        PRIOR_PARAMS['theta_sd'] * torch.ones(n_features, device=device)).to_event(1))\n",
    "    \n",
    "    # Linear predictors\n",
    "    eta_D = torch.matmul(X, theta_D)\n",
    "    eta_P = torch.matmul(X, theta_P)\n",
    "    \n",
    "    # Hazards\n",
    "    log_h_D = lognormal_log_hazard(durations, mu_D, sigma_D) + eta_D\n",
    "    log_h_P = lognormal_log_hazard(durations, mu_P, sigma_P) + eta_P\n",
    "    H_D = lognormal_cumulative_hazard(durations, mu_D, sigma_D) * torch.exp(eta_D)\n",
    "    H_P = lognormal_cumulative_hazard(durations, mu_P, sigma_P) * torch.exp(eta_P)\n",
    "    \n",
    "    # Log-likelihood\n",
    "    log_lik = (events == 2).float() * log_h_D + (events == 1).float() * log_h_P - H_D - H_P\n",
    "    pyro.factor('log_likelihood', torch.sum(log_lik))\n",
    "\n",
    "print(f\"Model parameters: {4 + 2*len(feature_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mcmc-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## MCMC Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-mcmc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MCMC\n",
    "print(f\"Running MCMC on {DEVICE}...\")\n",
    "pyro.clear_param_store()\n",
    "\n",
    "X_train_torch = torch.tensor(X_train, dtype=torch.float32, device=DEVICE)\n",
    "duration_train_torch = torch.tensor(duration_train, dtype=torch.float32, device=DEVICE)\n",
    "event_train_torch = torch.tensor(event_train, dtype=torch.int64, device=DEVICE)\n",
    "\n",
    "mcmc = MCMC(\n",
    "    NUTS(bayesian_competing_risks_model, target_accept_prob=MCMC_PARAMS['target_accept_prob'], jit_compile=False),\n",
    "    num_samples=MCMC_PARAMS['num_samples'],\n",
    "    warmup_steps=MCMC_PARAMS['num_warmup'],\n",
    "    num_chains=MCMC_PARAMS['num_chains'],\n",
    ")\n",
    "\n",
    "mcmc.run(X=X_train_torch, durations=duration_train_torch, events=event_train_torch, n_features=X_train.shape[1])\n",
    "print(\"MCMC completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mcmc-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get posterior samples\n",
    "mcmc.summary()\n",
    "posterior_samples = {k: v.cpu().numpy() for k, v in mcmc.get_samples().items()}\n",
    "inference_data = az.from_pyro(mcmc)\n",
    "\n",
    "print(\"\\nPosterior shapes:\")\n",
    "for k, v in posterior_samples.items():\n",
    "    print(f\"  {k}: {v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trace-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace plots\n",
    "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "for i, param in enumerate(['mu_D', 'sigma_D', 'mu_P', 'sigma_P']):\n",
    "    samples = posterior_samples[param]\n",
    "    axes[0, i].plot(samples, alpha=0.7)\n",
    "    axes[0, i].set_title(f'Trace: {param}')\n",
    "    axes[1, i].hist(samples, bins=50, density=True, alpha=0.7)\n",
    "    axes[1, i].axvline(np.mean(samples), color='red', linestyle='--')\n",
    "    axes[1, i].set_title(f'Posterior: {param}')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'bayesian_trace_baseline.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coefficient-summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient summaries\n",
    "baseline_df = pd.DataFrame([{\n",
    "    'Parameter': p, 'Mean': np.mean(posterior_samples[p]), 'Median': np.median(posterior_samples[p]),\n",
    "    'CI_2.5%': np.percentile(posterior_samples[p], 2.5), 'CI_97.5%': np.percentile(posterior_samples[p], 97.5)\n",
    "} for p in ['mu_D', 'sigma_D', 'mu_P', 'sigma_P']])\n",
    "print(baseline_df.to_string(index=False))\n",
    "\n",
    "coef_summary_D = [{'Feature': f, 'Mean': np.mean(posterior_samples['theta_D'][:, i]),\n",
    "    'CI_2.5%': np.percentile(posterior_samples['theta_D'][:, i], 2.5),\n",
    "    'CI_97.5%': np.percentile(posterior_samples['theta_D'][:, i], 97.5),\n",
    "    'Significant': not (np.percentile(posterior_samples['theta_D'][:, i], 2.5) < 0 < np.percentile(posterior_samples['theta_D'][:, i], 97.5))\n",
    "} for i, f in enumerate(feature_cols)]\n",
    "\n",
    "coef_summary_P = [{'Feature': f, 'Mean': np.mean(posterior_samples['theta_P'][:, i]),\n",
    "    'CI_2.5%': np.percentile(posterior_samples['theta_P'][:, i], 2.5),\n",
    "    'CI_97.5%': np.percentile(posterior_samples['theta_P'][:, i], 97.5),\n",
    "    'Significant': not (np.percentile(posterior_samples['theta_P'][:, i], 2.5) < 0 < np.percentile(posterior_samples['theta_P'][:, i], 97.5))\n",
    "} for i, f in enumerate(feature_cols)]\n",
    "\n",
    "coef_df_D, coef_df_P = pd.DataFrame(coef_summary_D), pd.DataFrame(coef_summary_P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prediction-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Model Wrapper & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "model-wrapper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model wrapper for evaluation module\n",
    "class BayesianModelWrapper:\n",
    "    def __init__(self, posterior_samples, device='cpu'):\n",
    "        self.posterior_samples_ = posterior_samples\n",
    "        self.device = device\n",
    "    \n",
    "    def predict_cif(self, X, times, cause='default'):\n",
    "        X = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        times = torch.tensor(times, dtype=torch.float32, device=self.device)\n",
    "        N, T = X.shape[0], len(times)\n",
    "        \n",
    "        ps = {k: torch.tensor(v, device=self.device) for k, v in self.posterior_samples_.items()}\n",
    "        n_samples = len(ps['mu_D'])\n",
    "        cif_samples = np.zeros((n_samples, N, T))\n",
    "        \n",
    "        for s in range(n_samples):\n",
    "            eta_D = torch.matmul(X, ps['theta_D'][s])\n",
    "            eta_P = torch.matmul(X, ps['theta_P'][s])\n",
    "            for t_idx, t in enumerate(times):\n",
    "                H_D = lognormal_cumulative_hazard(t, ps['mu_D'][s], ps['sigma_D'][s]) * torch.exp(eta_D)\n",
    "                H_P = lognormal_cumulative_hazard(t, ps['mu_P'][s], ps['sigma_P'][s]) * torch.exp(eta_P)\n",
    "                S_t = torch.exp(-H_D - H_P)\n",
    "                cif = (H_D if cause == 'default' else H_P) / (H_D + H_P + 1e-10) * (1 - S_t)\n",
    "                cif_samples[s, :, t_idx] = cif.cpu().numpy()\n",
    "        \n",
    "        return np.mean(cif_samples, 0), np.percentile(cif_samples, 2.5, 0), np.percentile(cif_samples, 97.5, 0)\n",
    "    \n",
    "    def predict_survival(self, X, times):\n",
    "        X = torch.tensor(X, dtype=torch.float32, device=self.device)\n",
    "        times = torch.tensor(times, dtype=torch.float32, device=self.device)\n",
    "        N, T = X.shape[0], len(times)\n",
    "        \n",
    "        ps = {k: torch.tensor(v, device=self.device) for k, v in self.posterior_samples_.items()}\n",
    "        n_samples = len(ps['mu_D'])\n",
    "        surv_samples = np.zeros((n_samples, N, T))\n",
    "        \n",
    "        for s in range(n_samples):\n",
    "            eta_D = torch.matmul(X, ps['theta_D'][s])\n",
    "            eta_P = torch.matmul(X, ps['theta_P'][s])\n",
    "            for t_idx, t in enumerate(times):\n",
    "                H_D = lognormal_cumulative_hazard(t, ps['mu_D'][s], ps['sigma_D'][s]) * torch.exp(eta_D)\n",
    "                H_P = lognormal_cumulative_hazard(t, ps['mu_P'][s], ps['sigma_P'][s]) * torch.exp(eta_P)\n",
    "                surv_samples[s, :, t_idx] = torch.exp(-H_D - H_P).cpu().numpy()\n",
    "        \n",
    "        return np.mean(surv_samples, 0), np.percentile(surv_samples, 2.5, 0), np.percentile(surv_samples, 97.5, 0)\n",
    "\n",
    "model = BayesianModelWrapper(posterior_samples, device='cpu')\n",
    "print(\"Model wrapper created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute-predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute predictions\n",
    "time_points = np.linspace(1, 180, 100)\n",
    "cif_default_mean, cif_default_lower, cif_default_upper = model.predict_cif(X_test, time_points, 'default')\n",
    "cif_prepay_mean, cif_prepay_lower, cif_prepay_upper = model.predict_cif(X_test, time_points, 'prepay')\n",
    "surv_mean, surv_lower, surv_upper = model.predict_survival(X_test, time_points)\n",
    "print(f\"Predictions computed: CIF shape {cif_default_mean.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-predictions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot sample predictions\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "sample_idx = np.random.choice(len(X_test), 5, replace=False)\n",
    "\n",
    "for idx in sample_idx:\n",
    "    axes[0].plot(time_points, cif_prepay_mean[idx], alpha=0.7)\n",
    "    axes[1].plot(time_points, cif_default_mean[idx], alpha=0.7)\n",
    "    axes[2].plot(time_points, surv_mean[idx], alpha=0.7)\n",
    "\n",
    "axes[0].set_title('Prepayment CIF'); axes[1].set_title('Default CIF'); axes[2].set_title('Survival')\n",
    "for ax in axes: ax.set_xlabel('Time (months)'); ax.grid(True, alpha=0.3); ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'bayesian_survival_curves.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Performance Evaluation (using bayesian_evaluation module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "run-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive evaluation using the module\n",
    "print(\"Running comprehensive evaluation...\\n\")\n",
    "\n",
    "eval_results = evaluate_bayesian_model(\n",
    "    model=model,\n",
    "    X_train=X_train, durations_train=duration_train, events_train=event_train,\n",
    "    X_test=X_test, durations_test=duration_test, events_test=event_test,\n",
    "    time_horizons=TIME_HORIZONS,\n",
    "    causes=['default', 'prepay']\n",
    ")\n",
    "\n",
    "print(format_evaluation_results(eval_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-cindex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot C-index\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "horizons = TIME_HORIZONS\n",
    "x = np.arange(len(horizons))\n",
    "width = 0.35\n",
    "\n",
    "prepay_vals = [eval_results['cindex']['prepay'].get(h, np.nan) for h in horizons]\n",
    "default_vals = [eval_results['cindex']['default'].get(h, np.nan) for h in horizons]\n",
    "\n",
    "ax.bar(x - width/2, prepay_vals, width, label='Prepayment', color='steelblue')\n",
    "ax.bar(x + width/2, default_vals, width, label='Default', color='indianred')\n",
    "ax.axhline(0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "ax.set_xticks(x); ax.set_xticklabels([f'τ={h}' for h in horizons])\n",
    "ax.set_ylabel('C-index (IPCW)'); ax.set_ylim(0.4, 1.0); ax.legend()\n",
    "ax.set_title('Bayesian PHM: Time-Dependent C-index')\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'bayesian_time_dependent_cindex.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plot-calibration",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibration plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "for row, cause in enumerate(['prepay', 'default']):\n",
    "    for col, tau in enumerate(TIME_HORIZONS):\n",
    "        ax = axes[row, col]\n",
    "        cal = eval_results['calibration'][cause].get(tau, {})\n",
    "        if 'predicted_mean' in cal:\n",
    "            pred, obs = cal['predicted_mean'], cal['observed_rate']\n",
    "            valid = ~np.isnan(obs)\n",
    "            if valid.sum() > 0:\n",
    "                ax.scatter(pred[valid], obs[valid], alpha=0.7, s=100)\n",
    "                ax.plot([0, 1], [0, 1], 'k--', alpha=0.5)\n",
    "        ax.set_title(f'{cause.capitalize()} τ={tau}')\n",
    "        ax.set_xlabel('Predicted'); ax.set_ylabel('Observed')\n",
    "plt.suptitle('Calibration Plots', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIGURES_DIR / 'bayesian_calibration.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save-results",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save artifacts\n",
    "np.savez(MODELS_DIR / 'bayesian_phm_posterior.npz', **posterior_samples)\n",
    "inference_data.to_netcdf(MODELS_DIR / 'bayesian_phm_inference.nc')\n",
    "coef_df_D.to_csv(MODELS_DIR / 'bayesian_phm_coef_default.csv', index=False)\n",
    "coef_df_P.to_csv(MODELS_DIR / 'bayesian_phm_coef_prepay.csv', index=False)\n",
    "baseline_df.to_csv(MODELS_DIR / 'bayesian_phm_baseline.csv', index=False)\n",
    "pd.DataFrame(eval_results['cindex']).to_csv(MODELS_DIR / 'bayesian_phm_cindex.csv')\n",
    "with open(MODELS_DIR / 'bayesian_phm_scaler.pkl', 'wb') as f: pickle.dump(scaler, f)\n",
    "with open(MODELS_DIR / 'bayesian_phm_features.pkl', 'wb') as f: pickle.dump(feature_cols, f)\n",
    "print(f\"Results saved to {MODELS_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary-header",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "summary",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"BAYESIAN COMPETING RISKS PHM - SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nInference: MCMC (NUTS via Pyro/PyTorch)\")\n",
    "print(f\"Data: Train {len(train_df):,}, Test {len(test_df):,}\")\n",
    "print(f\"Features: {len(feature_cols)}\")\n",
    "print(f\"\\nC-index (IPCW):\")\n",
    "for cause in ['prepay', 'default']:\n",
    "    print(f\"  {cause.upper()}:\")\n",
    "    for tau, c in eval_results['cindex'][cause].items():\n",
    "        print(f\"    τ={tau}: {c:.4f}\")\n",
    "print(f\"\\nSignificant covariates:\")\n",
    "print(f\"  Default: {', '.join([c['Feature'] for c in coef_summary_D if c['Significant']]) or 'None'}\")\n",
    "print(f\"  Prepay: {', '.join([c['Feature'] for c in coef_summary_P if c['Significant']]) or 'None'}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
